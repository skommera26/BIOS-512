{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d684172-4b94-42cf-bda2-e11952420d86",
   "metadata": {},
   "source": [
    "# Homework 10\n",
    "#### Course Notes\n",
    "**Language Models:** https://github.com/rjenki/BIOS512/tree/main/lecture17  \n",
    "**Unix:** https://github.com/rjenki/BIOS512/tree/main/lecture18  \n",
    "**Docker:** https://github.com/rjenki/BIOS512/tree/main/lecture19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d839a5ba-62f4-4699-baea-018afda70786",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "#### Make a language model that uses ngrams and allows the user to specify start words, but uses a random start if one is not specified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49",
   "metadata": {},
   "source": [
    "#### a) Make a function to tokenize the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42a37e68-f690-4a24-9a14-e0de7bd06f99",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in library(tokenizers): there is no package called ‘tokenizers’\n",
     "output_type": "error",
     "traceback": [
      "Error in library(tokenizers): there is no package called ‘tokenizers’\nTraceback:\n",
      "1. stop(packageNotFoundError(package, lib.loc, sys.call()))"
     ]
    }
   ],
   "source": [
    "# loading libraries\n",
    "\n",
    "library(httr)\n",
    "library(tokenizers)\n",
    "library(stringr)\n",
    "\n",
    "token_text <- tokenizers::tokenize_words(text, lowercase=TRUE, strip_punct=TRUE)[[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86145513-294b-4894-a02c-8ae60e2c616e",
   "metadata": {},
   "source": [
    "#### b) Make a function generate keys for ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5704a576-c087-4303-b956-82b8e22fa6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys <- function(ngram, sep=\"\\x1f\"){\n",
    "    paste(ngram, collapse=sep)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52988c2c-b230-467f-b519-72bc85b93b43",
   "metadata": {},
   "source": [
    "#### c) Make a function to build an ngram table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b74bbfdb-acb2-46eb-953d-08eb9e522e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_table <- function(tokens, n, sep = \"\\x1f\") {\n",
    "    if (length(tokens) < n) return(new.env(parent = emptyenv()))\n",
    "    tbl <- new.env(parent = emptyenv())\n",
    "    for (i in seq_len(length(tokens) - n + 1L)) {\n",
    "        ngram <- tokens[i:(i + n - 2L)]\n",
    "        next_word <- tokens[i + n - 1L]\n",
    "        key <- paste(ngram, collapse = sep)\n",
    "        counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
    "        if (next_word %in% names(counts)) {\n",
    "            counts[[next_word]] <- counts[[next_word]] + 1L\n",
    "        } else {\n",
    "            counts[[next_word]] <- 1L\n",
    "        }\n",
    "        tbl[[key]] <- counts\n",
    "    }\n",
    "    tbl\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca6db37-abce-4705-9784-e1b898174f00",
   "metadata": {},
   "source": [
    "#### d) Function to digest the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72412a17-65e5-4fa0-a3f9-a6a80d073dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "digest_text <- function(text,n){\n",
    "    token <- token_text(text)\n",
    "    ngram_table(token,n)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fff313-0f13-479b-94df-7588c19fdd3d",
   "metadata": {},
   "source": [
    "#### e) Function to digest the url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c2a1755-c749-4d42-9dda-38e010f9a12d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in parse(text = input): <text>:1:30: unexpected '{'\n1: digest_url <- fucntion(url,n){\n                                 ^\n",
     "output_type": "error",
     "traceback": [
      "Error in parse(text = input): <text>:1:30: unexpected '{'\n1: digest_url <- fucntion(url,n){\n                                 ^\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "digest_url <- fucntion(url,n){\n",
    "    res <- httr::GET(url) # the httr:: means refering to that specific package and askign to get fucntion from that package\n",
    "    txt <- httr::content(res, as = \"text\", encoding = \"UTF-8\")\n",
    "    digest_text(txt,n)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a",
   "metadata": {},
   "source": [
    "#### f) Function that gives random start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5af0445-4242-4712-950b-78c4660c736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start <- function(tbl, sep = \"\\x1f\"){\n",
    "    keys <- ls(envir=tbl, all.names = TRUE)\n",
    "    if (length(keys) == 0) stop(\"No n-grams available. Digest text first.\")\n",
    "    picked <- sample(keys,1)\n",
    "    strsplit(picked, sep, fixed = TRUE) [[1]]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e998fb24-f2d6-41bc-a751-1f6accd3411f",
   "metadata": {},
   "source": [
    "#### g) Function to predict the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f9f0cad-c017-413f-8620-f1b8fc2b7854",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in parse(text = input): <text>:1:49: unexpected '{'\n1: next_word <- fucntion(tbl, ngram, sep = \"\\x1f\") {\n                                                    ^\n",
     "output_type": "error",
     "traceback": [
      "Error in parse(text = input): <text>:1:49: unexpected '{'\n1: next_word <- fucntion(tbl, ngram, sep = \"\\x1f\") {\n                                                    ^\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "next_word <- fucntion(tbl, ngram, sep = \"\\x1f\") {\n",
    "    key <- paste(ngram, collapse = sep)\n",
    "    counts <- if(!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
    "    if (length(counts) == 0) return(NA_character_)\n",
    "    sample(names(counts), size=1, prob=as.numeric(counts))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347f4002-4932-42c4-a4af-8689293a5857",
   "metadata": {},
   "source": [
    "#### h) Function that puts everything together. Specify that if the user does not give a start word, then the random start will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0deb668-29f3-4768-8c11-4a55527296fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_ngram_generator <- function(tbl, n, sep = \"\\x1f\") {\n",
    "    force(tbl); n <- as.integer(n); force(sep)\n",
    "    function(start_words = NULL, length = 10L) {\n",
    "        if ((is.null(start_words)) || length(start_words) != n - 1L) {\n",
    "            start_words <- start(tbl, sep=sep)\n",
    "        }\n",
    "        word_sequence <- start_words\n",
    "        for (i in seq_len(max(0L, length - length(start_words)))) {\n",
    "            ngram <- tail(word_sequence, n - 1L)\n",
    "            next_word <- next_word(tbl, ngram, sep=sep)\n",
    "            if (is.na(next_word)) break\n",
    "            word_sequence <- c(word_sequence, next_word)\n",
    "        }\n",
    "        paste(word_sequence, collapse= \" \")\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b742c67-907c-4bc7-8df1-c84fa65a7554",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "#### For this question, set `seed=2025`.\n",
    "#### a) Test your model using a text file of [Grimm's Fairy Tails](https://www.gutenberg.org/cache/epub/2591/pg2591.txt)\n",
    "#### i) Using n=3, with the start word(s) \"the king\", with length=15. \n",
    "#### ii) Using n=3, with no start word, with length=15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88137de0-6ec9-4e0a-8c06-035f56cfd26c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in digest_url(url, n = 3): could not find function \"digest_url\"\n",
     "output_type": "error",
     "traceback": [
      "Error in digest_url(url, n = 3): could not find function \"digest_url\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "set.seed(2025)\n",
    "\n",
    "url <- \"https://www.gutenberg.org/cache/epub/2591/pg2591.txt\"\n",
    "\n",
    "#i) \n",
    "url3 <- digest_url(url,n=3)\n",
    "ngram3 <- make_ngram_generator(url3,n=3)\n",
    "ngram3(start_words = \"the king\",length=15)\n",
    "\n",
    "#ii)\n",
    "nostrt_url3 <- digest_url(url,n=3)\n",
    "nostrt_ngram3 <- make_ngram_generator(nostrt_url3,n=3)\n",
    "nostrt_ngram3(length=15)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e04b167-7f2c-4e0f-88e7-86ba5e8d74cc",
   "metadata": {},
   "source": [
    "#### b) Test your model using a text file of [Ancient Armour and Weapons in Europe](https://www.gutenberg.org/cache/epub/46342/pg46342.txt)\n",
    "#### i) Using n=3, with the start word(s) \"the king\", with length=15. \n",
    "#### ii) Using n=3, with no start word, with length=15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a35a9a93-30c0-4b25-b35a-d05d8bc8bbc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in digest_url(url, n = 3): could not find function \"digest_url\"\n",
     "output_type": "error",
     "traceback": [
      "Error in digest_url(url, n = 3): could not find function \"digest_url\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "url <- \"https://www.gutenberg.org/cache/epub/2591/pg2591.txt\"\n",
    "\n",
    "#i) \n",
    "url3 <- digest_url(url,n=3)\n",
    "ngram3 <- make_ngram_generator(url3,n=3)\n",
    "ngram3(start_words = \"the king\",length=15)\n",
    "\n",
    "#ii)\n",
    "nostrt_url3 <- digest_url(url,n=3)\n",
    "nostrt_ngram3 <- make_ngram_generator(nostrt_url3,n=3)\n",
    "nostrt_ngram3(length=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fb37ad-8e7c-4e62-afc0-ba46d46401fc",
   "metadata": {},
   "source": [
    "#### c) Explain in 1-2 sentences the difference in content generated from each source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8102b95-7854-4148-b5b8-ae129cfd299d",
   "metadata": {},
   "source": [
    "*A:* The difference between each source is that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e45972-f441-4d07-9073-fcddd6146cbd",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "#### a) What is a language learning model? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47770f19-f87f-49f3-bcac-354997b64172",
   "metadata": {},
   "source": [
    "*A:* A language learning model is a probability distribution over words that predicts the most likley word that would come next given a set of words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcc8088-d1ed-45be-8541-8df0d14853dc",
   "metadata": {},
   "source": [
    "#### b) Imagine the internet goes down and you can't run to your favorite language model for help. How do you run one locally?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b9119b-01f3-4028-b4ee-81806b09ef3d",
   "metadata": {},
   "source": [
    "*A:* To run one locally, you would use downloaded packages and software that include AI software that can then be loaded and run locally on one's computer.  An example of this would be Ollama that can be run locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85a743b-f814-4a53-96e6-8bccb3d34ab8",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "#### Explain what the following vocab words mean in the context of typing `mkdir project` into the command line. If the term doesn't apply to this command, give the definition and/or an example.\n",
    "| Term | Meaning |  \n",
    "|------|---------|\n",
    "| **Shell** | The shell helps create that connection between what we typed and sends it to the computer to execute |\n",
    "| **Terminal emulator** | This sits between operating system and the user to help create the program to be ran by the command given by the user|\n",
    "| **Process** | The process running on our computer is mkdir to make a directory called project  |\n",
    "| **Signal** | In this case there is no singal becasue mkdir is a command, but and example would be ^C to interupt the process telling it to die  |\n",
    "| **Standard input** | The standard input would help read the commands given by user|\n",
    "| **Standard output** | The standard output of this would help create the output from the commands given by user |\n",
    "| **Command line argument** | Here the command line argument is mkdir project |\n",
    "| **The environment** | The environment is created when the process we put into the terminal is ran |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1332ff27-ca3f-4f7e-b4b9-07ead0358dd2",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "#### Consider the following command `find . -iname \"*.R\" | xargs grep read_csv`.\n",
    "#### a) What are the programs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a865a99-c2f6-4c17-a212-7a53dab70c8e",
   "metadata": {},
   "source": [
    "*A:* The programs it is referring to here are R programs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84404045-e0a6-4af5-88d9-1ec5e5535482",
   "metadata": {},
   "source": [
    "#### b) Explain what this command is doing, part by part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c737cc-46b2-4849-94c5-e0d344119f13",
   "metadata": {},
   "source": [
    "*A:* The line is telling the shell to first find files such that they are .R files. Then take the output of that, pipe into next segment which will find arguments within the file that have read_csv and print those out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69771ac7-865e-4d82-aa25-a39e7c1ab095",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "#### Install Docker on your machine. See [here](https://github.com/rjenki/BIOS512/blob/main/lecture18/docker_install.md) for instructions. \n",
    "#### a) Show the response when you run `docker run hello-world`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555bcdd0-f8b1-428d-9560-b9bd71b164e0",
   "metadata": {},
   "source": [
    "Hello from Docker!\n",
    "This message shows that your installation appears to be working correctly.\n",
    "\n",
    "To generate this message, Docker took the following steps:\n",
    " 1. The Docker client contacted the Docker daemon.\n",
    " 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
    "    (arm64v8)\n",
    " 3. The Docker daemon created a new container from that image which runs the\n",
    "    executable that produces the output you are currently reading.\n",
    " 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
    "    to your terminal.\n",
    "\n",
    "To try something more ambitious, you can run an Ubuntu container with:\n",
    " $ docker run -it ubuntu bash\n",
    "\n",
    "Share images, automate workflows, and more with a free Docker ID:\n",
    " https://hub.docker.com/\n",
    "\n",
    "For more examples and ideas, visit:\n",
    " https://docs.docker.com/get-started/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5367a1be-5e3d-4052-a4a7-9cb49573e75f",
   "metadata": {},
   "source": [
    "#### b) Access Rstudio through a Docker container. Set your password and make sure your files show up on the Rstudio server. Type the command and the output you get below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23576e4b-d1ca-4733-963f-b70464fefe52",
   "metadata": {},
   "source": [
    "*A:* Commands used: \n",
    "Docker run --platform linux/amd64 -it rocker/verse /bin/bash <br>\n",
    "docker run --platform linux/amd64 -it -p 8787:8787 rocker/verse<br>\n",
    "\n",
    "\n",
    "The output I got from the first one was lots od downloading item but here is output for second one:<br>\n",
    "\n",
    "[s6-init] making user provided files available at /var/run/s6/etc...exited 0.<br>\n",
    "[s6-init] ensuring user provided files have correct perms...exited 0.<br>\n",
    "[fix-attrs.d] applying ownership & permissions fixes...<br>\n",
    "[fix-attrs.d] done.<br>\n",
    "[cont-init.d] executing container initialization scripts...<br>\n",
    "[cont-init.d] 01_set_env: executing... <br>\n",
    "skipping /var/run/s6/container_environment/HOME<br>\n",
    "skipping /var/run/s6/container_environment/RSTUDIO_VERSION<br>\n",
    "[cont-init.d] 01_set_env: exited 0.<br>\n",
    "[cont-init.d] 02_userconf: executing... <br>\n",
    "\n",
    "\n",
    "The password is set to eing6Wiuquosh4Ra<br>\n",
    "If you want to set your own password, set the PASSWORD environment variable. e.g. run with:<br>\n",
    "docker run -e PASSWORD=<YOUR_PASS> -p 8787:8787 rocker/rstudio<br>\n",
    "\n",
    "\n",
    "[cont-init.d] 02_userconf: exited 0.<br>\n",
    "[cont-init.d] done.<br>\n",
    "[services.d] starting services<br>\n",
    "[services.d] done.<br>\n",
    "TTY detected. Printing informational message about logging configuration. Logging configuration loaded from '/etc/rstudio/logging.conf'. Logging to 'syslog'.<br>\n",
    "TTY detected. Printing informational message about logging configuration. Logging configuration loaded from '/etc/rstudio/logging.conf'. Logging to 'syslog'.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0a32bb-51aa-4e88-821b-9bdcfd05f0a9",
   "metadata": {},
   "source": [
    "#### c) How do you log in to the RStudio server?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc9c7b4-5035-4073-ba54-579af397652c",
   "metadata": {},
   "source": [
    "*A:* You log into the RStudio server by going to http://localhost:8787/ and logging in with username rstudio, since that is the idername we set, and using the password provided.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
